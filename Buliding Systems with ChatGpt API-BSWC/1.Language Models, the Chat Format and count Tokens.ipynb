{"cells":[{"cell_type":"markdown","id":"ae5bcee9-6588-4d29-bbb9-6fb351ef6630","metadata":{"id":"ae5bcee9-6588-4d29-bbb9-6fb351ef6630"},"source":["# L1 Language Models, the Chat Format and Tokens"]},{"cell_type":"markdown","id":"0c797991-8486-4d79-8c1d-5dc0c1289c2f","metadata":{"id":"0c797991-8486-4d79-8c1d-5dc0c1289c2f"},"source":["## Setup\n","#### Load the API key and relevant Python libaries.\n","In this course, we've provided some code that loads the OpenAI API key for you."]},{"cell_type":"code","execution_count":null,"id":"19cd4e96","metadata":{"height":149,"id":"19cd4e96"},"outputs":[],"source":["import os\n","import openai\n","openai.api_key  = 'please use your key'\n","\n","#openai.api_key  = os.environ['OPENAI_API_KEY']"]},{"cell_type":"markdown","id":"47ba0938-7ca5-46c4-a9d1-b55708d4dc7c","metadata":{"id":"47ba0938-7ca5-46c4-a9d1-b55708d4dc7c"},"source":["#### helper function\n","Low Temperature (e.g., 0.2): The model tends to produce more focused and deterministic output. It is more likely to choose the most probable next word based on its training data.\n","\n","Medium Temperature (e.g., 0.5): A balance between randomness and focus. It allows for some variability in the output, making it less predictable than low temperature but not as random as high temperature.\n","\n","High Temperature (e.g., 0.8 or 1.0): The output becomes more creative and diverse. The model is more likely to introduce less common words and phrases, resulting in more varied and sometimes unpredictable output."]},{"cell_type":"code","execution_count":null,"id":"1ed96988","metadata":{"height":166,"id":"1ed96988"},"outputs":[],"source":["def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n","    messages = [{\"role\": \"user\", \"content\": prompt}]\n","    response = openai.ChatCompletion.create(\n","        model=model,\n","        messages=messages,\n","        temperature=0,\n","    )\n","    return response.choices[0].message[\"content\"]"]},{"cell_type":"markdown","id":"fe10a390-2461-447d-bf8b-8498db404c44","metadata":{"id":"fe10a390-2461-447d-bf8b-8498db404c44"},"source":["## Prompt the model and get a completion"]},{"cell_type":"code","execution_count":null,"id":"e1cc57b2","metadata":{"height":47,"id":"e1cc57b2"},"outputs":[],"source":["response = get_completion(\"What is the capital of France?\")"]},{"cell_type":"code","execution_count":null,"id":"76774108","metadata":{"height":30,"id":"76774108","outputId":"202778b4-6206-4481-9114-32b4650d87fd"},"outputs":[{"name":"stdout","output_type":"stream","text":["The capital of France is Paris.\n"]}],"source":["print(response)"]},{"cell_type":"markdown","id":"b83d4e38-3e3c-4c5a-a949-040a27f29d63","metadata":{"id":"b83d4e38-3e3c-4c5a-a949-040a27f29d63"},"source":["## Tokens"]},{"cell_type":"code","execution_count":null,"id":"cc2d9e40","metadata":{"height":81,"id":"cc2d9e40","outputId":"36dfdd49-735e-4564-e870-c0a53f105139"},"outputs":[{"name":"stdout","output_type":"stream","text":["The reversed letters of \"lollipop\" are \"pillipol\".\n"]}],"source":["response = get_completion(\"Take the letters in lollipop \\\n","and reverse them\")\n","print(response)"]},{"cell_type":"markdown","id":"9d2b14d0-749d-4a79-9812-7b00ace9ae6f","metadata":{"id":"9d2b14d0-749d-4a79-9812-7b00ace9ae6f"},"source":["\"lollipop\" in reverse should be \"popillol\""]},{"cell_type":"code","execution_count":null,"id":"37cab84f","metadata":{"height":64,"id":"37cab84f"},"outputs":[],"source":["response = get_completion(\"\"\"Take the letters in \\\n","l-o-l-l-i-p-o-p and reverse them\"\"\")"]},{"cell_type":"code","execution_count":null,"id":"1577c561","metadata":{"height":30,"id":"1577c561","outputId":"71d6aec3-2be3-4be4-dae7-2f681b889b26"},"outputs":[{"data":{"text/plain":["'p-o-p-i-l-l-o-l'"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["response"]},{"cell_type":"markdown","id":"c8b88940-d3ab-4c00-b5c0-31531deaacbd","metadata":{"id":"c8b88940-d3ab-4c00-b5c0-31531deaacbd"},"source":["## Helper function (chat format)\n","Here's the helper function we'll use in this course."]},{"cell_type":"code","execution_count":null,"id":"8f89efad","metadata":{"height":217,"id":"8f89efad"},"outputs":[],"source":["def get_completion_from_messages(messages,\n","                                 model=\"gpt-3.5-turbo\",\n","                                 temperature=0,\n","                                 max_tokens=500):\n","    response = openai.ChatCompletion.create(\n","        model=model,\n","        messages=messages,\n","        temperature=temperature, # this is the degree of randomness of the model's output\n","        max_tokens=max_tokens, # the maximum number of tokens the model can ouptut\n","    )\n","    return response.choices[0].message[\"content\"]"]},{"cell_type":"code","execution_count":null,"id":"b28c3424","metadata":{"height":200,"id":"b28c3424","outputId":"9301c102-cf55-417b-fdbf-9446da1e5dab"},"outputs":[{"name":"stdout","output_type":"stream","text":["Oh, this carrot so jolly, so bright and so orange,\n","With a smile on its face, just like happy sunshine.\n","It grew in the garden, with love from the soil,\n","And now it brings joy with its sweet carrot coil.\n","\n","Its greens are so luscious, reaching up to the sky,\n","Bouncing in the breeze as the clouds float on by.\n","It dances with glee when the rain starts to pour,\n","For it knows it will grow, even more and more.\n","\n","With each little crunch, its flavor rings true,\n","A burst of delight that brings happiness too.\n","It crunches and munches, so full of good cheer,\n","A happy carrot, always spreading joy near.\n","\n","So let's celebrate this veggie so grand,\n","With its vibrant color and taste quite grand.\n","For a happy carrot brings smiles and delight,\n","A simple pleasure that feels just right.\n"]}],"source":["messages =  [\n","{'role':'system',\n"," 'content':\"\"\"You are an assistant who\\\n"," responds in the style of Dr Seuss.\"\"\"},\n","{'role':'user',\n"," 'content':\"\"\"write me a very short poem\\\n"," about a happy carrot\"\"\"},\n","]\n","response = get_completion_from_messages(messages, temperature=1)\n","print(response)"]},{"cell_type":"code","execution_count":null,"id":"56c6978d","metadata":{"height":200,"id":"56c6978d","outputId":"cde52c89-2fcd-4a03-f14f-2788a146c009"},"outputs":[{"name":"stdout","output_type":"stream","text":["Once upon a time, there was a carrot named Charlie who lived in a garden where all the vegetables were happy and enjoyed their days in the sun.\n"]}],"source":["# length\n","messages =  [\n","{'role':'system',\n"," 'content':'All your responses must be \\\n","one sentence long.'},\n","{'role':'user',\n"," 'content':'write me a story about a happy carrot'},\n","]\n","response = get_completion_from_messages(messages, temperature =1)\n","print(response)"]},{"cell_type":"code","execution_count":null,"id":"14fd6331","metadata":{"height":234,"id":"14fd6331","outputId":"08e33699-6b32-42e3-8417-181d19a70204"},"outputs":[{"name":"stdout","output_type":"stream","text":["Once there was a happy carrot named Larry, who grew tall and orange and never felt contrary.\n"]}],"source":["# combined\n","messages =  [\n","{'role':'system',\n"," 'content':\"\"\"You are an assistant who \\\n","responds in the style of Dr Seuss. \\\n","All your responses must be one sentence long.\"\"\"},\n","{'role':'user',\n"," 'content':\"\"\"write me a story about a happy carrot\"\"\"},\n","]\n","response = get_completion_from_messages(messages,\n","                                        temperature =1)\n","print(response)"]},{"cell_type":"code","execution_count":null,"id":"89a70c79","metadata":{"height":387,"id":"89a70c79"},"outputs":[],"source":["def get_completion_and_token_count(messages,\n","                                   model=\"gpt-3.5-turbo\",\n","                                   temperature=0,\n","                                   max_tokens=500):\n","\n","    response = openai.ChatCompletion.create(\n","        model=model,\n","        messages=messages,\n","        temperature=temperature,\n","        max_tokens=max_tokens,\n","    )\n","\n","    content = response.choices[0].message[\"content\"]\n","\n","    token_dict = {\n","'prompt_tokens':response['usage']['prompt_tokens'],\n","'completion_tokens':response['usage']['completion_tokens'],\n","'total_tokens':response['usage']['total_tokens'],\n","    }\n","\n","    return content, token_dict"]},{"cell_type":"code","execution_count":null,"id":"a64cf3c6","metadata":{"height":183,"id":"a64cf3c6"},"outputs":[],"source":["messages = [\n","{'role':'system',\n"," 'content':\"\"\"You are an assistant who responds\\\n"," in the style of Dr Seuss.\"\"\"},\n","{'role':'user',\n"," 'content':\"\"\"write me a very short poem \\\n"," about a happy carrot\"\"\"},\n","]\n","response, token_dict = get_completion_and_token_count(messages)"]},{"cell_type":"code","execution_count":null,"id":"cfd8fbd4","metadata":{"height":30,"id":"cfd8fbd4","outputId":"b855bd75-553d-4d49-b315-c304d89771a5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Oh, the happy carrot, so bright and orange,\n","Grown in the garden, a joyful forage.\n","With a smile so wide, from top to bottom,\n","It brings happiness, oh how it blossoms!\n","\n","In the soil it grew, with love and care,\n","Nurtured by sunshine, fresh air to share.\n","Its leaves so green, reaching up so high,\n","A happy carrot, oh my, oh my!\n","\n","With a crunch and a munch, it's oh so tasty,\n","Filled with vitamins, oh so hasty.\n","A healthy snack, a delight to eat,\n","The happy carrot, oh so sweet!\n","\n","So let's celebrate this veggie delight,\n","With every bite, a happy sight.\n","For the happy carrot, we give a cheer,\n","A joyful veggie, oh so dear!\n"]}],"source":["print(response)"]},{"cell_type":"code","execution_count":null,"id":"352ad320","metadata":{"height":30,"id":"352ad320","outputId":"6b50a4f1-211d-4644-fd75-32de5d016885"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'prompt_tokens': 37, 'completion_tokens': 160, 'total_tokens': 197}\n"]}],"source":["print(token_dict)"]},{"cell_type":"markdown","id":"65372cdd-d869-4768-947a-0173e7f96335","metadata":{"id":"65372cdd-d869-4768-947a-0173e7f96335"},"source":["#### Notes on using the OpenAI API outside of this classroom\n","\n","To install the OpenAI Python library:\n","```\n","!pip install openai\n","```\n","\n","The library needs to be configured with your account's secret key, which is available on the [website](https://platform.openai.com/account/api-keys).\n","\n","You can either set it as the `OPENAI_API_KEY` environment variable before using the library:\n"," ```\n"," !export OPENAI_API_KEY='sk-...'\n"," ```\n","\n","Or, set `openai.api_key` to its value:\n","\n","```\n","import openai\n","openai.api_key = \"sk-...\"\n","```"]},{"cell_type":"markdown","id":"d8f889c1-f2e4-40a5-bd27-164facb54402","metadata":{"id":"d8f889c1-f2e4-40a5-bd27-164facb54402"},"source":["#### A note about the backslash\n","- In the course, we are using a backslash `\\` to make the text fit on the screen without inserting newline '\\n' characters.\n","- GPT-3 isn't really affected whether you insert newline characters or not.  But when working with LLMs in general, you may consider whether newline characters in your prompt may affect the model's performance."]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}
